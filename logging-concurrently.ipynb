{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging Concurrently\n",
    "\n",
    "Once we've got the hang of using `rubicon`, we can expand on our project from the *Iris Classifier* example. \n",
    "Let's see how a few other popular `scikit-learn` models perform with the Iris dataset. `rubicon` logging is totally \n",
    "thread-safe, so we can test a lot of model configurations at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T13:25:15.408752Z",
     "iopub.status.busy": "2021-04-07T13:25:15.407655Z",
     "iopub.status.idle": "2021-04-07T13:25:16.098695Z",
     "shell.execute_reply": "2021-04-07T13:25:16.098155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project(name='Concurrent Experiments', id='f1f03f82-6d41-4d57-b733-07ea8954061e', description='Training multiple models in parallel', github_url=None, training_metadata=None, created_at=datetime.datetime(2021, 4, 7, 13, 25, 16, 91674))\n"
     ]
    }
   ],
   "source": [
    "from rubicon import Rubicon\n",
    "\n",
    "root_dir = \"./rubicon-root\"\n",
    "\n",
    "rubicon = Rubicon(persistence=\"filesystem\", root_dir=root_dir)\n",
    "project = rubicon.create_project(\"Concurrent Experiments\", description=\"Training multiple models in parallel\")\n",
    "\n",
    "print(project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a recap of the contents of the Iris dataset, check out `iris.DESCR` and `iris.data`. We'll put together\n",
    "a training dataset using a subset of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T13:25:16.103807Z",
     "iopub.status.busy": "2021-04-07T13:25:16.103195Z",
     "iopub.status.idle": "2021-04-07T13:25:16.550728Z",
     "shell.execute_reply": "2021-04-07T13:25:16.551202Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state = int(datetime.utcnow().timestamp())\n",
    "\n",
    "iris = load_iris()\n",
    "iris_datasets = train_test_split(iris['data'], iris['target'], random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use `run_experiment` to log a new experiment to the provided `project` then train, run and log a model of type\n",
    "`classifier_cls` using the training and testing data in `iris_datasets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T13:25:16.560048Z",
     "iopub.status.busy": "2021-04-07T13:25:16.558690Z",
     "iopub.status.idle": "2021-04-07T13:25:16.560668Z",
     "shell.execute_reply": "2021-04-07T13:25:16.561107Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "\n",
    "SklearnTrainingMetadata = namedtuple(\"SklearnTrainingMetadata\", \"module_name method\")\n",
    "\n",
    "def run_experiment(project, classifier_cls, iris_datasets, **kwargs):\n",
    "    X_train, X_test, y_train, y_test = iris_datasets\n",
    "    \n",
    "    experiment = project.log_experiment(\n",
    "        training_metadata=[SklearnTrainingMetadata(\"sklearn.datasets\", \"load_iris\")],\n",
    "        model_name=classifier_cls.__name__,\n",
    "        tags=[classifier_cls.__name__],\n",
    "    )\n",
    "    \n",
    "    for key, value in kwargs.items():\n",
    "        experiment.log_parameter(key, value)\n",
    "    \n",
    "    n_features = len(iris.feature_names)\n",
    "    experiment.log_parameter(\"n_features\", n_features)\n",
    "    \n",
    "    for name in iris.feature_names:\n",
    "        experiment.log_feature(name)\n",
    "        \n",
    "    classifier = classifier_cls(**kwargs)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    classifier.predict(X_test)\n",
    "    \n",
    "    accuracy = classifier.score(X_test, y_test)\n",
    "    \n",
    "    experiment.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    if accuracy >= .95:\n",
    "        experiment.add_tags([\"success\"])\n",
    "    else:\n",
    "        experiment.add_tags([\"failure\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we'll take a look at two more classifiers, **decision tree** and **k-neighbors**, in addition to the **random forest** classifier we used in the last example. Each classifier will be ran across four sets of parameters (provided as `kwargs` to `run_experiment`), for a total of 12 experiments. Here, we'll build up a list of processes that will run each experiment in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T13:25:16.568993Z",
     "iopub.status.busy": "2021-04-07T13:25:16.568424Z",
     "iopub.status.idle": "2021-04-07T13:25:16.615882Z",
     "shell.execute_reply": "2021-04-07T13:25:16.615127Z"
    }
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "processes = []\n",
    "\n",
    "for n_estimators in [10, 20, 30, 40]:\n",
    "    processes.append(multiprocessing.Process(\n",
    "        target=run_experiment, args=[project, RandomForestClassifier, iris_datasets],\n",
    "        kwargs={\"n_estimators\": n_estimators, \"random_state\": random_state},\n",
    "    ))\n",
    "    \n",
    "for criterion in [\"gini\", \"entropy\"]:\n",
    "    for splitter in [\"best\", \"random\"]:\n",
    "        processes.append(multiprocessing.Process(\n",
    "            target=run_experiment, args=[project, DecisionTreeClassifier, iris_datasets],\n",
    "            kwargs={\"criterion\": criterion, \"splitter\": splitter, \"random_state\": random_state},\n",
    "        ))\n",
    "\n",
    "for n_neighbors in [5, 10, 15, 20]:\n",
    "    processes.append(multiprocessing.Process(\n",
    "        target=run_experiment, args=[project, KNeighborsClassifier, iris_datasets],\n",
    "        kwargs={\"n_neighbors\": n_neighbors},\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run all our experiments in parallel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T13:25:16.622323Z",
     "iopub.status.busy": "2021-04-07T13:25:16.619972Z",
     "iopub.status.idle": "2021-04-07T13:25:16.847592Z",
     "shell.execute_reply": "2021-04-07T13:25:16.846846Z"
    }
   },
   "outputs": [],
   "source": [
    "for process in processes:\n",
    "    process.start()\n",
    "    \n",
    "for process in processes:\n",
    "    process.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can validate that we successfully logged all 12 experiments to our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T13:25:16.853686Z",
     "iopub.status.busy": "2021-04-07T13:25:16.853181Z",
     "iopub.status.idle": "2021-04-07T13:25:16.867944Z",
     "shell.execute_reply": "2021-04-07T13:25:16.867437Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(project.experiments())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see which experiments we tagged as successful and what type of model they used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T13:25:16.872062Z",
     "iopub.status.busy": "2021-04-07T13:25:16.871498Z",
     "iopub.status.idle": "2021-04-07T13:25:16.910371Z",
     "shell.execute_reply": "2021-04-07T13:25:16.909905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment 06083a1a-8d01-4afd-b0ef-369927a050c0 was successful using a KNeighborsClassifier\n",
      "experiment 081c5770-d5c2-45ea-bc6d-178b351b78f4 was successful using a RandomForestClassifier\n",
      "experiment 0ec0abe6-474d-4a6c-982c-d12c98a1e8fa was successful using a RandomForestClassifier\n",
      "experiment 11dc8dfe-4ce2-4bb8-bfb2-974f0533f1a1 was successful using a RandomForestClassifier\n",
      "experiment 27f7e6b3-3abf-444d-99ae-055934e327af was successful using a KNeighborsClassifier\n",
      "experiment 41508b92-c978-45f1-8112-b36af3058d63 was successful using a DecisionTreeClassifier\n",
      "experiment 416bf002-824f-4567-93bf-49e0ff931fd3 was successful using a RandomForestClassifier\n",
      "experiment 4cd0c9ab-ad01-4512-83d8-18159daa6572 was successful using a KNeighborsClassifier\n",
      "experiment 83526856-8f62-4308-b455-b3aa263dafd1 was successful using a DecisionTreeClassifier\n",
      "experiment a49df240-fb65-4bc8-b1a6-616b23d7cf26 was successful using a KNeighborsClassifier\n",
      "experiment b56e835e-0a05-47e5-9295-8c8a2e100537 was successful using a DecisionTreeClassifier\n",
      "experiment eef0c762-124d-4171-a52d-b01f1631d92f was successful using a DecisionTreeClassifier\n"
     ]
    }
   ],
   "source": [
    "for e in project.experiments(tags=[\"success\"]):    \n",
    "    print(f\"experiment {e.id} was successful using a {e.model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take a deeper look at any of our experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T13:25:16.915334Z",
     "iopub.status.busy": "2021-04-07T13:25:16.914882Z",
     "iopub.status.idle": "2021-04-07T13:25:16.923612Z",
     "shell.execute_reply": "2021-04-07T13:25:16.923110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_metadata: SklearnTrainingMetadata(module_name='sklearn.datasets', method='load_iris')\n",
      "tags: ['success', 'KNeighborsClassifier']\n",
      "parameters:\n",
      "\tn_features: 4\n",
      "\tn_neighbors: 5\n",
      "features:\n",
      "\tpetal length (cm)\n",
      "\tpetal width (cm)\n",
      "\tsepal length (cm)\n",
      "\tsepal width (cm)\n",
      "metrics:\n",
      "\taccuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "experiment = project.experiments()[0]\n",
    "\n",
    "print(f\"training_metadata: {SklearnTrainingMetadata(*experiment.training_metadata)}\")\n",
    "print(f\"tags: {experiment.tags}\")\n",
    "print(\"parameters:\")\n",
    "for parameter in experiment.parameters():\n",
    "    print(f\"\\t{parameter.name}: {parameter.value}\")\n",
    "print(\"features:\")\n",
    "for feature in experiment.features():\n",
    "    print(f\"\\t{feature.name}\")\n",
    "print(\"metrics:\")\n",
    "for metric in experiment.metrics():\n",
    "    print(f\"\\t{metric.name}: {metric.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model developers can take advantage of `rubicon`'s thread-safety to test tons of models at once and collect results\n",
    "in a standardized format to analyze which ones performed the best. `rubicon` can even be run in more advanced\n",
    "distributed setups, like on a *Dask* cluster."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "nbsphinx": {
   "execute": "always"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
