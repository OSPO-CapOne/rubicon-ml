{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging Concurrently\n",
    "\n",
    "Once we've got the hang of using `rubicon`, we can expand on our project from the *Iris Classifier* example. \n",
    "Let's see how a few other popular `scikit-learn` models perform with the Iris dataset. `rubicon` logging is totally \n",
    "thread-safe, so we can test a lot of model configurations at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-05T18:15:15.406014Z",
     "iopub.status.busy": "2021-04-05T18:15:15.405239Z",
     "iopub.status.idle": "2021-04-05T18:15:16.198029Z",
     "shell.execute_reply": "2021-04-05T18:15:16.197367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project(name='Concurrent Experiments', id='4e8ba1ae-ecf8-4976-9650-9ba3701a4fc3', description='Training multiple models in parallel', github_url=None, training_metadata=None, created_at=datetime.datetime(2021, 4, 5, 18, 15, 16, 189837))\n"
     ]
    }
   ],
   "source": [
    "from rubicon import Rubicon\n",
    "\n",
    "root_dir = \"./rubicon-root\"\n",
    "\n",
    "rubicon = Rubicon(persistence=\"filesystem\", root_dir=root_dir)\n",
    "project = rubicon.create_project(\"Concurrent Experiments\", description=\"Training multiple models in parallel\")\n",
    "\n",
    "print(project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a recap of the contents of the Iris dataset, check out `iris.DESCR` and `iris.data`. We'll put together\n",
    "a training dataset using a subset of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-05T18:15:16.203524Z",
     "iopub.status.busy": "2021-04-05T18:15:16.202546Z",
     "iopub.status.idle": "2021-04-05T18:15:16.644534Z",
     "shell.execute_reply": "2021-04-05T18:15:16.643980Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state = int(datetime.utcnow().timestamp())\n",
    "\n",
    "iris = load_iris()\n",
    "iris_datasets = train_test_split(iris['data'], iris['target'], random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use `run_experiment` to log a new experiment to the provided `project` then train, run and log a model of type\n",
    "`classifier_cls` using the training and testing data in `iris_datasets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-05T18:15:16.652978Z",
     "iopub.status.busy": "2021-04-05T18:15:16.651548Z",
     "iopub.status.idle": "2021-04-05T18:15:16.653612Z",
     "shell.execute_reply": "2021-04-05T18:15:16.654074Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "\n",
    "SklearnTrainingMetadata = namedtuple(\"SklearnTrainingMetadata\", \"module_name method\")\n",
    "\n",
    "def run_experiment(project, classifier_cls, iris_datasets, **kwargs):\n",
    "    X_train, X_test, y_train, y_test = iris_datasets\n",
    "    \n",
    "    experiment = project.log_experiment(\n",
    "        training_metadata=[SklearnTrainingMetadata(\"sklearn.datasets\", \"load_iris\")],\n",
    "        model_name=classifier_cls.__name__,\n",
    "        tags=[classifier_cls.__name__],\n",
    "    )\n",
    "    \n",
    "    for key, value in kwargs.items():\n",
    "        experiment.log_parameter(key, value)\n",
    "    \n",
    "    n_features = len(iris.feature_names)\n",
    "    experiment.log_parameter(\"n_features\", n_features)\n",
    "    \n",
    "    for name in iris.feature_names:\n",
    "        experiment.log_feature(name)\n",
    "        \n",
    "    classifier = classifier_cls(**kwargs)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    classifier.predict(X_test)\n",
    "    \n",
    "    accuracy = classifier.score(X_test, y_test)\n",
    "    \n",
    "    experiment.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    if accuracy >= .95:\n",
    "        experiment.add_tags([\"success\"])\n",
    "    else:\n",
    "        experiment.add_tags([\"failure\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we'll take a look at two more classifiers, **decision tree** and **k-neighbors**, in addition to the **random forest** classifier we used in the last example. Each classifier will be ran across four sets of parameters (provided as `kwargs` to `run_experiment`), for a total of 12 experiments. Here, we'll build up a list of processes that will run each experiment in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-05T18:15:16.660903Z",
     "iopub.status.busy": "2021-04-05T18:15:16.660322Z",
     "iopub.status.idle": "2021-04-05T18:15:16.704444Z",
     "shell.execute_reply": "2021-04-05T18:15:16.703885Z"
    }
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "processes = []\n",
    "\n",
    "for n_estimators in [10, 20, 30, 40]:\n",
    "    processes.append(multiprocessing.Process(\n",
    "        target=run_experiment, args=[project, RandomForestClassifier, iris_datasets],\n",
    "        kwargs={\"n_estimators\": n_estimators, \"random_state\": random_state},\n",
    "    ))\n",
    "    \n",
    "for criterion in [\"gini\", \"entropy\"]:\n",
    "    for splitter in [\"best\", \"random\"]:\n",
    "        processes.append(multiprocessing.Process(\n",
    "            target=run_experiment, args=[project, DecisionTreeClassifier, iris_datasets],\n",
    "            kwargs={\"criterion\": criterion, \"splitter\": splitter, \"random_state\": random_state},\n",
    "        ))\n",
    "\n",
    "for n_neighbors in [5, 10, 15, 20]:\n",
    "    processes.append(multiprocessing.Process(\n",
    "        target=run_experiment, args=[project, KNeighborsClassifier, iris_datasets],\n",
    "        kwargs={\"n_neighbors\": n_neighbors},\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run all our experiments in parallel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-05T18:15:16.709442Z",
     "iopub.status.busy": "2021-04-05T18:15:16.708859Z",
     "iopub.status.idle": "2021-04-05T18:15:16.951708Z",
     "shell.execute_reply": "2021-04-05T18:15:16.950684Z"
    }
   },
   "outputs": [],
   "source": [
    "for process in processes:\n",
    "    process.start()\n",
    "    \n",
    "for process in processes:\n",
    "    process.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can validate that we successfully logged all 12 experiments to our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-05T18:15:16.956579Z",
     "iopub.status.busy": "2021-04-05T18:15:16.955997Z",
     "iopub.status.idle": "2021-04-05T18:15:16.973452Z",
     "shell.execute_reply": "2021-04-05T18:15:16.972890Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(project.experiments())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see which experiments we tagged as successful and what type of model they used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-05T18:15:16.977960Z",
     "iopub.status.busy": "2021-04-05T18:15:16.977150Z",
     "iopub.status.idle": "2021-04-05T18:15:16.995707Z",
     "shell.execute_reply": "2021-04-05T18:15:16.995118Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment 05424cbd-beb4-4171-b75b-bfda5c6ba729 was successful using a RandomForestClassifier\n",
      "experiment 1cd670e8-745a-40de-89db-66d7704fb885 was successful using a RandomForestClassifier\n",
      "experiment 2bdb17d3-3c08-4245-b918-a0267db14c34 was successful using a RandomForestClassifier\n",
      "experiment 3ac29a9f-6043-4239-bc36-5cba4b64be11 was successful using a KNeighborsClassifier\n",
      "experiment 7334f1e3-129e-4681-a23e-0f41ae810535 was successful using a DecisionTreeClassifier\n",
      "experiment a12d8518-9d53-4b80-84ab-22be1f8b24e8 was successful using a RandomForestClassifier\n",
      "experiment b1940343-6c58-41f2-939b-05c2448ee94f was successful using a DecisionTreeClassifier\n",
      "experiment cee36678-90b2-46e1-b6be-e52b88871f1c was successful using a KNeighborsClassifier\n",
      "experiment ed3cba7a-da3d-4184-991d-58c03222d290 was successful using a KNeighborsClassifier\n",
      "experiment f15b95c9-4dfa-4b9a-9c89-8d703c9f2f0e was successful using a KNeighborsClassifier\n"
     ]
    }
   ],
   "source": [
    "for e in project.experiments(tags=[\"success\"]):    \n",
    "    print(f\"experiment {e.id} was successful using a {e.model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take a deeper look at any of our experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-05T18:15:17.001442Z",
     "iopub.status.busy": "2021-04-05T18:15:17.000868Z",
     "iopub.status.idle": "2021-04-05T18:15:17.013308Z",
     "shell.execute_reply": "2021-04-05T18:15:17.012257Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_metadata: SklearnTrainingMetadata(module_name='sklearn.datasets', method='load_iris')\n",
      "tags: ['RandomForestClassifier', 'success']\n",
      "parameters:\n",
      "\tn_estimators: 20\n",
      "\tn_features: 4\n",
      "\trandom_state: 1617646516\n",
      "features:\n",
      "\tpetal length (cm)\n",
      "\tpetal width (cm)\n",
      "\tsepal length (cm)\n",
      "\tsepal width (cm)\n",
      "metrics:\n",
      "\taccuracy: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "experiment = project.experiments()[0]\n",
    "\n",
    "print(f\"training_metadata: {SklearnTrainingMetadata(*experiment.training_metadata)}\")\n",
    "print(f\"tags: {experiment.tags}\")\n",
    "print(\"parameters:\")\n",
    "for parameter in experiment.parameters():\n",
    "    print(f\"\\t{parameter.name}: {parameter.value}\")\n",
    "print(\"features:\")\n",
    "for feature in experiment.features():\n",
    "    print(f\"\\t{feature.name}\")\n",
    "print(\"metrics:\")\n",
    "for metric in experiment.metrics():\n",
    "    print(f\"\\t{metric.name}: {metric.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model developers can take advantage of `rubicon`'s thread-safety to test tons of models at once and collect results\n",
    "in a standardized format to analyze which ones performed the best. `rubicon` can even be run in more advanced\n",
    "distributed setups, like on a *Dask* cluster."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "nbsphinx": {
   "execute": "always"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
